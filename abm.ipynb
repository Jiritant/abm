{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mesa import Agent, Model\n",
    "from mesa.time import SimultaneousActivation\n",
    "from mesa.space import MultiGrid\n",
    "from mesa.datacollection import DataCollector\n",
    "from mesa.visualization.modules import CanvasGrid, ChartModule\n",
    "from mesa.visualization.ModularVisualization import ModularServer\n",
    "from mesa.visualization.UserParam import Choice\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearningAgent(Agent):\n",
    "    def __init__(self, unique_id, model, row, learning_model):\n",
    "        super().__init__(unique_id, model)\n",
    "        self.row = row\n",
    "        self.learning_model = learning_model  # 'RW' or 'TD'\n",
    "        self.learning_rate = 0.1 # Rate of learning\n",
    "        self.extinction_rate = 1.0 # Standard for RW extinction = 1, typically <1\n",
    "        self.delta = 0.0 # Standard for delta = 0. Standard logstic for delta = 1, S-curve 0 < delta < 1\n",
    "        self.beta = 1.0 # Responsivity to food in TD learning\n",
    "        self.affect = 0.01 # Initial value outcome RW learning\n",
    "        self.value_low = 0.0  # Initial value outcome TD learning\n",
    "        self.value_high = 0.0 # Initial value outcome TD learning\n",
    "        self.pcolor = None  # The current patch color where the agent is located\n",
    "        self.food_consumed = None  # Food consumed status ('L' or 'H')\n",
    "        self.p_low = 0.2  # True reward value of food type L\n",
    "        self.p_high = 0.8  # True reward value of food type H\n",
    "        self.lambda_val = 0.8  # Max reward for RW model\n",
    "\n",
    "    def step(self): # Move agent to the right in grid space\n",
    "        x, y = self.pos\n",
    "        new_x = (x + 1) % self.model.grid.width\n",
    "        self.model.grid.move_agent(self, (new_x, y))\n",
    "        #print(f\"I ate {str(self.food_consumed)}\")\n",
    "        #print(f\"My TD reward learning is: {str(self.value_high)}\")\n",
    "        #print(f\"My RW reward learning is: {str(self.affect)}\")\n",
    "\n",
    "        #Get current patch color\n",
    "        self.pcolor = self.model.grid.get_cell_list_contents([self.pos])[0].type\n",
    "\n",
    "        # Determine food consumed based on patch type\n",
    "        if self.pcolor == 'HH':\n",
    "            self.food_consumed = 'H'\n",
    "        elif self.pcolor == 'LL':\n",
    "            self.food_consumed = 'L'\n",
    "        else:\n",
    "            self.food_consumed = random.choice(['H', 'L']) #FOR NOW RANDOM. WILL DEPEND ON LEARNING MODELS.\n",
    "\n",
    "        #Update learning\n",
    "        if self.learning_model == 'RW':\n",
    "            self.update_affect_rw()\n",
    "        elif self.learning_model == 'TD':\n",
    "            self.update_reward_td()\n",
    "\n",
    "    def update_affect_rw(self):\n",
    "        if self.food_consumed == 'H':\n",
    "            self.affect += self.affect + (self.learning_rate * (self.affect ** self.delta) * (self.lambda_val - self.affect))\n",
    "        else:\n",
    "            self.affect += self.affect + (self.learning_rate * (self.affect ** self.delta) * self.extinction_rate * (0 - self.affect))\n",
    "\n",
    "    def update_reward_td(self):\n",
    "        if self.food_consumed == 'L':\n",
    "            self.value_low += (self.value_low + self.learning_rate * (self.beta * self.p_low - self.value_low))\n",
    "        else:\n",
    "            self.value_high += (self.value_high + self.learning_rate * (self.beta * self.p_high - self.value_high))\n",
    "\n",
    "\n",
    "class Patch(Agent):\n",
    "    def __init__(self, unique_id, model, patch_type):\n",
    "        super().__init__(unique_id, model)\n",
    "        self.type = patch_type\n",
    "\n",
    "    def get_color(self):\n",
    "        if self.type == \"HH\":\n",
    "            return \"red\"\n",
    "        elif self.type == \"LL\":\n",
    "            return \"blue\"\n",
    "        elif self.type == \"HL\":\n",
    "            return \"purple\"\n",
    "        return \"white\"\n",
    "    \n",
    "class LearningModel(Model):\n",
    "    def __init__(self, N, width, height, learning_model='RW', distribute_patches = 'random'):\n",
    "        super().__init__()\n",
    "        self.num_agents = N\n",
    "        self.grid = MultiGrid(width, height, True)\n",
    "        self.schedule = SimultaneousActivation(self)\n",
    "        self.learning_model = learning_model\n",
    "\n",
    "        #Create agents \n",
    "        for i in range(self.num_agents):\n",
    "            agent = LearningAgent(i, self, row=i, learning_model=learning_model)\n",
    "            self.grid.place_agent(agent, (0, i))\n",
    "            self.schedule.add(agent)\n",
    "\n",
    "        #Add patches with types based on different distributions\n",
    "        if distribute_patches == 'random':\n",
    "            self.distribute_randomly()\n",
    "        elif distribute_patches == 'gradient_h':\n",
    "            self.distribute_gradient_h()\n",
    "        elif distribute_patches == 'gradient_l':\n",
    "            self.distribute_gradient_l()\n",
    "\n",
    "        self.datacollector = DataCollector(\n",
    "            agent_reporters={\"Affect\": \"affect\", \"Value_Low\": \"value_low\", \"Value_High\": \"value_high\"}\n",
    "        )\n",
    "\n",
    "    def distribute_randomly(self):\n",
    "        patch_types = [\"HH\", \"LL\", \"HL\"]\n",
    "        for x in range(self.grid.width):\n",
    "            for y in range(self.grid.height):\n",
    "                patch_type = random.choice(patch_types)\n",
    "                patch = Patch(f'patch_{x}_{y}', self, patch_type)\n",
    "                self.grid.place_agent(patch, (x,y))\n",
    "\n",
    "    def distribute_gradient_h(self):\n",
    "        for y in range(self.grid.height):\n",
    "            for x in range(self.grid.width):\n",
    "                prob_hh = x / self.grid.width\n",
    "                if random.random() < prob_hh:\n",
    "                    patch_type = \"HL\"\n",
    "                else:\n",
    "                    patch_type = \"HH\"\n",
    "                patch = Patch(f'patch_{x}_{y}', self, patch_type)\n",
    "                self.grid.place_agent(patch, (x, y))\n",
    "\n",
    "    \n",
    "    def distribute_gradient_l(self):\n",
    "        for y in range(self.grid.height):\n",
    "            for x in range(self.grid.width):\n",
    "                prob_ll = x / self.grid.width\n",
    "                if random.random() < prob_ll:\n",
    "                    patch_type = \"HL\"\n",
    "                else:\n",
    "                    patch_type = \"LL\"\n",
    "                patch = Patch(f'patch_{x}_{y}', self, patch_type)\n",
    "                self.grid.place_agent(patch, (x, y))\n",
    "\n",
    "    def step(self):\n",
    "        self.datacollector.collect(self)\n",
    "        self.schedule.step()\n",
    "\n",
    "    def visualize(self):\n",
    "        grid_matrix = []\n",
    "        for y in range(self.grid.height):\n",
    "            row = []\n",
    "            for x in range(self.grid.width):\n",
    "                cell_content = self.grid.get_cell_list_contents([(x,y)])\n",
    "                patch = next((obj for obj in cell_content if isinstance(obj, Patch)), None)\n",
    "                if patch:\n",
    "                    row.append(patch.get_color())\n",
    "                else:\n",
    "                    row.append(\"white\")\n",
    "            grid_matrix.append(row)\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(10, 10))\n",
    "        cmap = mcolors.ListedColormap(['red', 'blue', 'purple', 'white'])\n",
    "        bounds = [0, 1, 2, 3, 4]\n",
    "        norm = mcolors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "        matrix = [[bounds.index(cmap.colors.index(color)) for color in row] for row in grid_matrix]\n",
    "        ax.imshow(matrix, cmap = cmap, norm = norm)\n",
    "\n",
    "        plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the model\n",
    "model = LearningModel(N=100, width=100, height=100, learning_model='TD', distribute_patches = 'random')\n",
    "\n",
    "for i in range(100):\n",
    "    model.step()\n",
    "\n",
    "df1 = model.datacollector.get_agent_vars_dataframe()\n",
    "\n",
    "model.visualize() #In case you want to check distribution of food on map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "df2 = df1.reset_index()\n",
    "df2['avg_value'] = df2['Value_High'] / 100               \n",
    "\n",
    "print(df2.head())\n",
    "\n",
    "td = sns.lineplot(df2, x='Step', y = 'avg_value')\n",
    "plt.show(td)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent_portrayal(agent):\n",
    "    if isinstance(agent, Patch):\n",
    "        portrayal = {\"Shape\": \"rect\",\n",
    "                     \"Filled\": \"true\",\n",
    "                     \"Color\": agent.get_color(),\n",
    "                     \"Layer\": 0,\n",
    "                     \"w\": 1,\n",
    "                     \"h\": 1}\n",
    "    else:\n",
    "        portrayal = {\"Shape\": \"circle\",\n",
    "                     \"Filled\": \"true\",\n",
    "                     \"Color\": \"white\",\n",
    "                     \"Layer\": 1,\n",
    "                     \"r\": 1}\n",
    "    return portrayal\n",
    "\n",
    "# Create a grid visualization\n",
    "grid = CanvasGrid(agent_portrayal, 100, 100, 500, 500)\n",
    "\n",
    "# Create a chart for agent affects\n",
    "chart = ChartModule(\n",
    "    [{\"Label\": \"Affect\", \"Color\": \"Black\"}, {\"Label\": \"Value_Low\", \"Color\": \"Blue\"}, {\"Label\": \"Value_High\", \"Color\": \"Red\"}]\n",
    ")\n",
    "\n",
    "model_params = {\n",
    "    \"N\": 100,\n",
    "    \"width\": 100,\n",
    "    \"height\": 100,\n",
    "    \"learning_model\": Choice(\"Learning Model\", value=\"RW\", choices=[\"RW\", \"TD\"]),\n",
    "    \"distribute_patches\": Choice(\"Patch Distribution\", value=\"random\", choices=[\"random\", \"gradient_h\", \"gradient_l\"]),\n",
    "}\n",
    "\n",
    "server = ModularServer(LearningModel, [grid, chart], \"Learning Model\", model_params)\n",
    "server.port = 8521\n",
    "server.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
